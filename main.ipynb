{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0746b7f1-e66a-41d9-bbce-d60c2551cf3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "!git clone https://github.com/MaastrichtU-IDS/LMKBC-2023.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d05e67e-39f7-470c-8c1e-19775707b2db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git reset --hard\n",
    "!git pull -f https://github.com/MaastrichtU-IDS/LMKBC-2023.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef8c3b6-c9dc-495e-b844-fc353dadbaf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('LMKBC-2023/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5a2ecd7-70ce-45b1-9250-8b3375b928f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from accelerate) (23.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from accelerate) (5.9.4)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from accelerate) (2.0.0a0+1767026)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from accelerate) (1.22.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate) (3.10.0)\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate) (1.11.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate) (2.6.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-0.21.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m99.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m124.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.10.0)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Downloading safetensors-0.3.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m183.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.22.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.10.31)\n",
      "Collecting huggingface-hub<1.0,>=0.14.1\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m246.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.1.0)\n",
      "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.31.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate -U\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b789a5e4-ab2b-4301-8b79-a9cb11eb659c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    \n",
      "   python /workspace/persistent/LMKBC-2023/src/fm_model.py  --test_fn /workspace/persistent/LMKBC-2023/data/val.jsonl --template_fn res/prompts0.csv  --output_fn /workspace/persistent/LMKBC-2023/output/filled-mask-valid.jsonl --train_fn /workspace/persistent/LMKBC-2023/data/train.jsonl --train_batch_size 256 --gpu 0  --top_k 30 --threshold 0.1  --dev_fn  /workspace/persistent/LMKBC-2023/data/train_tiny.jsonl --mode \"train test\" --train_epoch 50 --learning_rate 5e-5 --model_load_dir bert-large-cased --model_save_dir /workspace/persistent/LMKBC-2023/bin/train_full/fill_mask/bert-large-cased --model_best_dir  /workspace/persistent/LMKBC-2023/bin/train_full/fill_mask/bert-large-cased/best_ckpt\n",
      "    \n",
      "    \n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/persistent/LMKBC-2023/src/fm_model.py\", line 11, in <module>\n",
      "    import transformers\n",
      "ModuleNotFoundError: No module named 'transformers'\n"
     ]
    }
   ],
   "source": [
    "!python src/run.py --mode \"train_fm\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f414398-b041-4bfc-8769-eafe32f05aba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11db8616-7f1c-46aa-8fad-8aaf98a3c643",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37ddf76e-10a3-439a-91a8-a941c44250e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 13ca210] from server\n",
      " 7 files changed, 264 insertions(+), 197 deletions(-)\n",
      " create mode 100644 logging/events.out.tfevents.1690042231.jupyterlab-gpu-3-zspsf.4406.0\n",
      " create mode 100644 logging/events.out.tfevents.1690043133.jupyterlab-gpu-3-zspsf.5294.0\n",
      " create mode 100644 logging/events.out.tfevents.1690100442.jupyterlab-gpu-3-zspsf.7581.0\n",
      " rewrite main.ipynb (92%)\n",
      " create mode 100644 src/nohup.out\n"
     ]
    }
   ],
   "source": [
    "!git add . \n",
    "!git commit -m 'from server' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a13d1898-9f78-4dc1-9e22-13209c33ec48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "{'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 29182, -100, -100], 'input_ids': [101, 1109, 3199, 1137, 1352, 33331, 6641, 1330, 1352, 1137, 3199, 103, 119, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1]}\n",
      "{\"SubjectEntityID\": \"Q16189274\", \"SubjectEntity\": \"Harsh Goenka\", \"ObjectEntitiesID\": [\"Q7277463\"], \"ObjectEntities\": [\"RPG Group\"], \"Relation\": \"PersonHasEmployer\"}{\"SubjectEntityID\": \"Q724465\", \"SubjectEntity\": \"Ket\", \"ObjectEntitiesID\": [\"Q159\"], \"ObjectEntities\": [\"Russia\"], \"Relation\": \"RiverBasinsCountry\"}\n",
      "\n",
      "{'labels': [-100, -100, -100, -100, -100, 31957, -100, -100, -100, -100, -100, -100, -100], 'input_ids': [101, 1109, 1583, 20325, 2075, 103, 1112, 1103, 1352, 1137, 3199, 119, 102], 'attention_mask': [1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1]}\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0%|                                                   | 0/800 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "{'loss': 10.3187, 'learning_rate': 1e-05, 'epoch': 1.0}                         \n",
      "{'loss': 6.777, 'learning_rate': 2e-05, 'epoch': 2.0}                           \n",
      "{'loss': 5.8615, 'learning_rate': 3e-05, 'epoch': 3.0}                          \n",
      "{'loss': 5.4373, 'learning_rate': 4e-05, 'epoch': 4.0}                          \n",
      "{'loss': 5.1076, 'learning_rate': 5e-05, 'epoch': 5.0}                          \n",
      "{'loss': 4.8422, 'learning_rate': 4.888888888888889e-05, 'epoch': 6.0}          \n",
      "{'loss': 4.6022, 'learning_rate': 4.7777777777777784e-05, 'epoch': 7.0}         \n",
      "{'loss': 4.4098, 'learning_rate': 4.666666666666667e-05, 'epoch': 8.0}          \n",
      "{'loss': 4.2327, 'learning_rate': 4.555555555555556e-05, 'epoch': 9.0}          \n",
      "{'loss': 4.0446, 'learning_rate': 4.4444444444444447e-05, 'epoch': 10.0}        \n",
      "{'loss': 3.8247, 'learning_rate': 4.3333333333333334e-05, 'epoch': 11.0}        \n",
      "{'loss': 3.5882, 'learning_rate': 4.222222222222222e-05, 'epoch': 12.0}         \n",
      "{'loss': 3.4393, 'learning_rate': 4.111111111111111e-05, 'epoch': 13.0}         \n",
      "{'loss': 3.2325, 'learning_rate': 4e-05, 'epoch': 14.0}                         \n",
      "{'loss': 3.0403, 'learning_rate': 3.888888888888889e-05, 'epoch': 15.0}         \n",
      "{'loss': 2.8399, 'learning_rate': 3.777777777777778e-05, 'epoch': 16.0}         \n",
      "{'loss': 2.6859, 'learning_rate': 3.6666666666666666e-05, 'epoch': 17.0}        \n",
      "{'loss': 2.5489, 'learning_rate': 3.555555555555556e-05, 'epoch': 18.0}         \n",
      "{'loss': 2.4187, 'learning_rate': 3.444444444444445e-05, 'epoch': 19.0}         \n",
      "{'loss': 2.2809, 'learning_rate': 3.3333333333333335e-05, 'epoch': 20.0}        \n",
      "{'loss': 2.1809, 'learning_rate': 3.222222222222223e-05, 'epoch': 21.0}         \n",
      "{'loss': 2.0817, 'learning_rate': 3.111111111111111e-05, 'epoch': 22.0}         \n",
      "{'loss': 2.0034, 'learning_rate': 3e-05, 'epoch': 23.0}                         \n",
      "{'loss': 1.9195, 'learning_rate': 2.8888888888888888e-05, 'epoch': 24.0}        \n",
      "{'loss': 1.8691, 'learning_rate': 2.777777777777778e-05, 'epoch': 25.0}         \n",
      "{'loss': 1.8068, 'learning_rate': 2.6666666666666667e-05, 'epoch': 26.0}        \n",
      "{'loss': 1.7543, 'learning_rate': 2.5555555555555554e-05, 'epoch': 27.0}        \n",
      "{'loss': 1.6984, 'learning_rate': 2.4444444444444445e-05, 'epoch': 28.0}        \n",
      "{'loss': 1.6454, 'learning_rate': 2.3333333333333336e-05, 'epoch': 29.0}        \n",
      "{'loss': 1.6216, 'learning_rate': 2.2222222222222223e-05, 'epoch': 30.0}        \n",
      "{'loss': 1.582, 'learning_rate': 2.111111111111111e-05, 'epoch': 31.0}          \n",
      "{'loss': 1.5503, 'learning_rate': 2e-05, 'epoch': 32.0}                         \n",
      "{'loss': 1.5301, 'learning_rate': 1.888888888888889e-05, 'epoch': 33.0}         \n",
      "{'loss': 1.5009, 'learning_rate': 1.777777777777778e-05, 'epoch': 34.0}         \n",
      "{'loss': 1.4783, 'learning_rate': 1.6666666666666667e-05, 'epoch': 35.0}        \n",
      "{'loss': 1.4694, 'learning_rate': 1.5555555555555555e-05, 'epoch': 36.0}        \n",
      "{'loss': 1.4548, 'learning_rate': 1.4444444444444444e-05, 'epoch': 37.0}        \n",
      "{'loss': 1.4433, 'learning_rate': 1.3333333333333333e-05, 'epoch': 38.0}        \n",
      "{'loss': 1.4208, 'learning_rate': 1.2222222222222222e-05, 'epoch': 39.0}        \n",
      "{'loss': 1.4148, 'learning_rate': 1.1111111111111112e-05, 'epoch': 40.0}        \n",
      "{'loss': 1.3973, 'learning_rate': 1e-05, 'epoch': 41.0}                         \n",
      "{'loss': 1.3684, 'learning_rate': 8.88888888888889e-06, 'epoch': 42.0}          \n",
      "{'loss': 1.3782, 'learning_rate': 7.777777777777777e-06, 'epoch': 43.0}         \n",
      "{'loss': 1.3688, 'learning_rate': 6.666666666666667e-06, 'epoch': 44.0}         \n",
      "{'loss': 1.3539, 'learning_rate': 5.555555555555556e-06, 'epoch': 45.0}         \n",
      "{'loss': 1.335, 'learning_rate': 4.444444444444445e-06, 'epoch': 46.0}          \n",
      "{'loss': 1.3346, 'learning_rate': 3.3333333333333333e-06, 'epoch': 47.0}        \n",
      "{'loss': 1.3314, 'learning_rate': 2.2222222222222225e-06, 'epoch': 48.0}        \n",
      "{'loss': 1.3158, 'learning_rate': 1.1111111111111112e-06, 'epoch': 49.0}        \n",
      "{'loss': 1.3209, 'learning_rate': 0.0, 'epoch': 50.0}                           \n",
      "{'train_runtime': 546.3116, 'train_samples_per_second': 369.112, 'train_steps_per_second': 1.464, 'train_loss': 2.649260184764862, 'epoch': 50.0}\n",
      "100%|█████████████████████████████████████████| 800/800 [09:06<00:00,  1.46it/s]\n",
      "model_best_dir:  /workspace/persistent/LMKBC-2023/bin/train_full/fill_mask/bert-large-cased/best_ckpt\n",
      "07/23/2023 14:16:53 - INFO - __main__ -  Running the model...\n",
      "07/23/2023 14:17:47 - INFO - __main__ -  End the model...\n",
      "07/23/2023 14:20:36 - INFO - __main__ -  Saving the results to \"/workspace/persistent/LMKBC-2023/output/filled-mask-valid.jsonl\"...\n",
      "07/23/2023 14:20:36 - INFO - __main__ -  Start Evaluate ...\n",
      "                                  p      r     f1\n",
      "BandHasMember                 0.000  0.001  0.001\n",
      "CityLocatedAtRiver            0.008  0.158  0.014\n",
      "CompanyHasParentOrganisation  0.020  0.598  0.039\n",
      "CompoundHasParts              0.102  0.952  0.183\n",
      "CountryBordersCountry         0.098  0.708  0.169\n",
      "CountryHasOfficialLanguage    0.043  0.813  0.079\n",
      "CountryHasStates              0.064  0.170  0.090\n",
      "FootballerPlaysPosition       0.036  0.980  0.070\n",
      "PersonCauseOfDeath            0.027  0.782  0.052\n",
      "PersonHasAutobiography        0.000  0.010  0.001\n",
      "PersonHasEmployer             0.003  0.042  0.005\n",
      "PersonHasNoblePrize           0.032  0.960  0.063\n",
      "PersonHasNumberOfChildren     0.033  0.980  0.064\n",
      "PersonHasPlaceOfDeath         0.019  0.556  0.036\n",
      "PersonHasProfession           0.026  0.340  0.047\n",
      "PersonHasSpouse               0.000  0.000  0.000\n",
      "PersonPlaysInstrument         0.063  0.956  0.115\n",
      "PersonSpeaksLanguage          0.046  0.848  0.086\n",
      "RiverBasinsCountry            0.033  0.710  0.063\n",
      "SeriesHasNumberOfEpisodes     0.030  0.890  0.057\n",
      "StateBordersState             0.006  0.043  0.009\n",
      "Average                       0.033  0.548  0.059\n",
      "                                  p      r     f1\n",
      "BandHasMember                 0.000  0.001  0.001\n",
      "CityLocatedAtRiver            0.008  0.158  0.014\n",
      "CompanyHasParentOrganisation  0.020  0.598  0.039\n",
      "CompoundHasParts              0.102  0.952  0.183\n",
      "CountryBordersCountry         0.098  0.708  0.169\n",
      "CountryHasOfficialLanguage    0.043  0.813  0.079\n",
      "CountryHasStates              0.064  0.170  0.090\n",
      "FootballerPlaysPosition       0.036  0.980  0.070\n",
      "PersonCauseOfDeath            0.027  0.782  0.052\n",
      "PersonHasAutobiography        0.000  0.010  0.001\n",
      "PersonHasEmployer             0.003  0.042  0.005\n",
      "PersonHasNoblePrize           0.032  0.960  0.063\n",
      "PersonHasNumberOfChildren     0.033  0.980  0.064\n",
      "PersonHasPlaceOfDeath         0.019  0.556  0.036\n",
      "PersonHasProfession           0.026  0.340  0.047\n",
      "PersonHasSpouse               0.000  0.000  0.000\n",
      "PersonPlaysInstrument         0.063  0.956  0.115\n",
      "PersonSpeaksLanguage          0.046  0.848  0.086\n",
      "RiverBasinsCountry            0.033  0.710  0.063\n",
      "SeriesHasNumberOfEpisodes     0.030  0.890  0.057\n",
      "StateBordersState             0.006  0.043  0.009\n",
      "Average                       0.033  0.548  0.059\n",
      "100%|██████████████████████████████████████████| 21/21 [00:00<00:00, 131.71it/s]\n",
      "                                 p     r    f1  best_topk  best_f1  origin_topk\n",
      "BandHasMember                 0.00  0.00  0.00       14.0     0.00         16.0\n",
      "CityLocatedAtRiver            0.01  0.16  0.01        2.0     0.05          5.0\n",
      "CompanyHasParentOrganisation  0.02  0.60  0.04        1.0     0.35          3.0\n",
      "CompoundHasParts              0.10  0.95  0.18        4.0     0.68          5.0\n",
      "CountryBordersCountry         0.10  0.71  0.17        5.0     0.38         10.0\n",
      "CountryHasOfficialLanguage    0.04  0.81  0.08        1.0     0.51         11.0\n",
      "CountryHasStates              0.06  0.17  0.09       16.0     0.10         20.0\n",
      "FootballerPlaysPosition       0.04  0.98  0.07        5.0     0.24          3.0\n",
      "PersonCauseOfDeath            0.03  0.78  0.05        1.0     0.63          3.0\n",
      "PersonHasAutobiography        0.00  0.01  0.00        1.0     0.01          4.0\n",
      "PersonHasEmployer             0.00  0.04  0.01       21.0     0.01         13.0\n",
      "PersonHasNoblePrize           0.03  0.96  0.06        1.0     0.46          2.0\n",
      "PersonHasNumberOfChildren     0.03  0.98  0.06        3.0     0.36          2.0\n",
      "PersonHasPlaceOfDeath         0.02  0.56  0.04        1.0     0.35          1.0\n",
      "PersonHasProfession           0.03  0.34  0.05        2.0     0.12         12.0\n",
      "PersonHasSpouse               0.00  0.00  0.00        0.0     0.00          3.0\n",
      "PersonPlaysInstrument         0.06  0.96  0.12        3.0     0.54          8.0\n",
      "PersonSpeaksLanguage          0.05  0.85  0.09        3.0     0.22          4.0\n",
      "RiverBasinsCountry            0.03  0.71  0.06        3.0     0.14          5.0\n",
      "SeriesHasNumberOfEpisodes     0.03  0.89  0.06        2.0     0.14          1.0\n",
      "StateBordersState             0.01  0.04  0.01       11.0     0.01         12.0\n",
      "Average                       0.03  0.55  0.06        NaN     0.25          NaN\n"
     ]
    }
   ],
   "source": [
    "!python /workspace/persistent/LMKBC-2023/src/fm_model.py  --test_fn /workspace/persistent/LMKBC-2023/data/val.jsonl --template_fn res/prompts0.csv  --output_fn /workspace/persistent/LMKBC-2023/output/filled-mask-valid.jsonl --train_fn /workspace/persistent/LMKBC-2023/data/train.jsonl --train_batch_size 256 --gpu 0  --top_k 30 --threshold 0.1  --dev_fn  /workspace/persistent/LMKBC-2023/data/train_tiny.jsonl --mode \"train test\"  --train_epoch 50 --learning_rate 5e-5   --model_load_dir  /workspace/persistent/LMKBC-2023/bin/train_full/pretrain_fill_mask/bert-large-cased/best_ckpt --model_save_dir  /workspace/persistent/LMKBC-2023/bin/train_full/fill_mask/bert-large-cased --model_best_dir  /workspace/persistent/LMKBC-2023/bin/train_full/fill_mask/bert-large-cased/best_ckpt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ea36e8-e98c-42a0-b841-b8a8607508e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08120826-d088-46da-97d2-507bd58c7d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc52855d-3ed9-4bc9-b4f6-0137d6fe5053",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
